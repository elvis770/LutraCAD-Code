{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'folder_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x6/vrfll5sx3fbbylywk6w9s0c00000gn/T/ipykernel_72048/3069568532.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mparam_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Merge the DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstl_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'folder name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Folder Number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'folder_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Rearrange columns according to the specified order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'folder name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'foot scan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MTP1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MTP5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HEEL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ARCH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ANKLE MEDIAL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ANKLE LATERAL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LENGTH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WIDTH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Parameters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'insole'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'folder_name'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Directory containing the folders\n",
    "base_dir = '/Users/elvisechefu/Desktop/LutraCAD2/Anonymous_20240507025011'\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "stl_data = []\n",
    "txt_data = []\n",
    "param_data = []\n",
    "\n",
    "# Loop through each folder\n",
    "for folder in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        foot_scan_stl = None\n",
    "        insole_stl = None\n",
    "        txt_file_data = None\n",
    "        param_data_item = None\n",
    "        \n",
    "        # Search for STL files within the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.stl'):\n",
    "                if \"library.stl\" in file:\n",
    "                    insole_stl = file\n",
    "                else:\n",
    "                    foot_scan_stl = file\n",
    "        \n",
    "        # Search for TXT files within the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.txt'):  # Check if the file has a .txt extension\n",
    "                txt_file_path = os.path.join(folder_path, file)\n",
    "                with open(txt_file_path, 'r') as file:\n",
    "                    details = {}\n",
    "                    for line in file:\n",
    "                        key, value = line.strip().split(':')\n",
    "                        details[key.strip()] = value.strip()\n",
    "                    txt_data.append([folder] + [details.get('MTP1'), details.get('MTP5'), details.get('HEEL'), details.get('ARCH'), details.get('ANKLE MEDIAL'), details.get('ANKLE LATERAL'), details.get('LENGTH'), details.get('WIDTH')])\n",
    "        \n",
    "        # Search for actions.dat files within the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name == \"actions.dat\":\n",
    "                actions_dat_file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Parse the actions.dat file\n",
    "                parsed_data = {\n",
    "                    \"folder_name\": os.path.basename(os.path.dirname(actions_dat_file_path)),\n",
    "                    \"HeelLift\": None,\n",
    "                    \"InsoleLength\": None,\n",
    "                    \"InsoleHeight\": None,\n",
    "                    \"TransformationData\": None,\n",
    "                    \"Parameters\": {\n",
    "                        \"SizeTable\": None,\n",
    "                        \"LengthInMM\": None,\n",
    "                        \"WidthInMM\": None,\n",
    "                        \"HeightInMM\": None,\n",
    "                        \"PatchSmooth\": None,\n",
    "                        \"PatchOffset\": None,\n",
    "                        \"SmoothFactor\": None,\n",
    "                        \"EnableFlatten\": None,\n",
    "                        \"Thickness\": None\n",
    "                    }\n",
    "                }\n",
    "                try:\n",
    "                    with open(actions_dat_file_path, 'r') as file:\n",
    "                        actions_dat_data = json.load(file)\n",
    "                        for item in actions_dat_data[\"List\"]:\n",
    "                            # Parse HeelLift data\n",
    "                            if item.get(\"Type\") == \"HeelLift\":\n",
    "                                heel_lift_data = {\n",
    "                                    \"Height\": item.get(\"Height\"),\n",
    "                                    \"Length\": item.get(\"Length\"),\n",
    "                                    \"Side\": item.get(\"Side\")\n",
    "                                }\n",
    "                                parsed_data[\"HeelLift\"] = heel_lift_data\n",
    "                            # Parse InsoleLength data\n",
    "                            elif item.get(\"Type\") == \"InsoleLength\":\n",
    "                                insole_length_data = {\n",
    "                                    \"Length\": item.get(\"Length\"),\n",
    "                                    \"Width\": item.get(\"Width\"),\n",
    "                                    \"Height\": item.get(\"Height\"),\n",
    "                                    \"Resources\": item.get(\"Resources\")\n",
    "                                }\n",
    "                                parsed_data[\"InsoleLength\"] = insole_length_data\n",
    "                            # Parse InsoleHeight data\n",
    "                            elif item.get(\"Type\") == \"InsoleHeight\":\n",
    "                                insole_height_data = {\n",
    "                                    \"Height\": item.get(\"Height\"),\n",
    "                                    \"Resources\": item.get(\"Resources\")\n",
    "                                }\n",
    "                                parsed_data[\"InsoleHeight\"] = insole_height_data\n",
    "                            # Parse Parameters data\n",
    "                            parameters = [\"SizeTable\", \"LengthInMM\", \"WidthInMM\", \"HeightInMM\", \"PatchSmooth\", \"PatchOffset\", \"SmoothFactor\", \"EnableFlatten\", \"Thickness\"]\n",
    "                            for param in parameters:\n",
    "                                if item.get(param) is not None:\n",
    "                                    parsed_data[\"Parameters\"][param] = item.get(param)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing actions.dat file: {e}\")\n",
    "                param_data.append(parsed_data)\n",
    "        \n",
    "        # Append data to STL DataFrame\n",
    "        stl_data.append([folder, foot_scan_stl, insole_stl])\n",
    "\n",
    "# Create DataFrames for the STL files, TXT files, and parameters\n",
    "stl_columns = ['folder name', 'foot scan', 'insole']\n",
    "stl_df = pd.DataFrame(stl_data, columns=stl_columns)\n",
    "\n",
    "txt_columns = ['Folder Number', 'MTP1', 'MTP5', 'HEEL', 'ARCH', 'ANKLE MEDIAL', 'ANKLE LATERAL', 'LENGTH', 'WIDTH']\n",
    "txt_df = pd.DataFrame(txt_data, columns=txt_columns)\n",
    "\n",
    "param_df = pd.DataFrame(param_data)\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(stl_df, txt_df, left_on='folder name', right_on='Folder Number', how='left')\n",
    "merged_df = pd.merge(merged_df, param_df, on='folder_name', how='left')\n",
    "\n",
    "# Rearrange columns according to the specified order\n",
    "merged_df = merged_df[['folder name', 'foot scan', 'MTP1', 'MTP5', 'HEEL', 'ARCH', 'ANKLE MEDIAL', 'ANKLE LATERAL', 'LENGTH', 'WIDTH', 'Parameters', 'insole']]\n",
    "\n",
    "# Save the merged DataFrame to CSV\n",
    "merged_df.to_csv('merged_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
